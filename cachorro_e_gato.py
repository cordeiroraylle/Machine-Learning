# -*- coding: utf-8 -*-
"""Cachorro e Gato.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZOG43uSdFuGu5stCKgT-ez53CCWVmoBx

# Cachorro e gato - Classificação


* É fofinho? **1**
* Tem orelha pequena? **1**
* Faz miau? 1

Caso contrário recebe 0 

* Gato = 1
* cachorro = -1
"""

from sklearn.linear_model import LogisticRegression as LR
from sklearn.naive_bayes import MultinomialNB as NB

bichinho1 = [1, 1, 1]
bichinho2 = [1, 0, 1]
bichinho3 = [0,1,1]
bichinho4 = [1, 1, 0]
bichinho5 = [0, 1, 0]
bichinho6 = [0,1,0]
bichinho7 = [0,0,0]

dados = [bichinho1,bichinho2, bichinho3, bichinho4, bichinho5,bichinho6,bichinho7]
marcacoes = [1, 1,1, -1, -1,-1,-1]

model = NB()
model.fit(dados, marcacoes)

misterioso = [0,0,0]
misterioso1 = [0,0,1]
misterioso2 =[0,1,0]
misterioso3= [0,1,1]
misterioso4 = [1,0,0]

teste = [misterioso, misterioso1,misterioso2,misterioso3, misterioso4]
#, misterioso2, misterioso3, misterioso4

#m1 = [0,1,1]
#m2 = [0,1,0]
#teste = [m1,m2]
previsao = model.predict(teste)

v_real = [-1,1,-1,1,-1]
correto = (previsao == v_real).sum()
acertos = (correto / len(teste))*100

qt = 0
qt_g = 0

for d in previsao:
  if d == -1:
    qt +=1
  else:
    qt_g +=1

print("Previsão encontrada:", previsao)
print("Resposta real:", v_real,"\n")
print("A taxa de acerto foi de {:.2f} %\n".format(acertos))

print("O algoritmo previu ",qt,"cachorros")
print("O algoritmo previu", qt_g, "gatos")